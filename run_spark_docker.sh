#!/usr/bin/env bash
set -euo pipefail

# --- 1) V√©rif des arguments ---
if [ $# -lt 1 ]; then
  echo "Usage: $0 <sbt_project_dir> [MainClass]"
  echo "ex:   $0 ex03_warehouse IngestToDWH"
  exit 1
fi

PROJECT_DIR="$1"
MAIN_CLASS="${2:-SparkApp}"

# Chemin absolu
PROJECT_DIR_ABS="$(cd "$PROJECT_DIR" && pwd)"

echo "[INFO] Projet : $PROJECT_DIR_ABS"
echo "[INFO] Classe principale : $MAIN_CLASS"

# V√©rifier si c'est un projet SQL pur (pas de build.sbt)
IS_SQL_ONLY=false
if [ ! -f "$PROJECT_DIR_ABS/build.sbt" ]; then
  echo "[INFO] üìã Projet SQL pur d√©tect√© (pas de build.sbt)"
  IS_SQL_ONLY=true
  JAR_NAME=""
else
  # --- 2) Plugin sbt-assembly ---
  PLUGINS_DIR="$PROJECT_DIR_ABS/project"
  PLUGINS_FILE="$PLUGINS_DIR/plugins.sbt"
  mkdir -p "$PLUGINS_DIR"

  if [ ! -f "$PLUGINS_FILE" ] || ! grep -q "sbt-assembly" "$PLUGINS_FILE" 2>/dev/null; then
    echo "[INFO] Ajout du plugin sbt-assembly..."
    cat >> "$PLUGINS_FILE" <<'EOF'
addSbtPlugin("com.eed3si9n" % "sbt-assembly" % "2.2.0")
EOF
  fi

  # --- 3) Build du fat JAR ---
  cd "$PROJECT_DIR_ABS"
  echo "[INFO] Compilation (sbt assembly)..."
  sbt -batch clean assembly

  # --- 4) Trouver le JAR ---
  JAR_PATH="$(find target -type f -name '*assembly*.jar' | sort | tail -n1 || true)"
  if [ -z "$JAR_PATH" ]; then
    echo "‚ùå Aucun JAR trouv√©."
    exit 1
  fi
  JAR_NAME="$(basename "$JAR_PATH")"
  echo "[INFO] JAR trouv√© : $JAR_NAME"

  # --- 5) Copie dans le conteneur ---
  echo "[INFO] Copie vers spark-master..."
  docker cp "$JAR_PATH" spark-master:/opt/spark/"$JAR_NAME"
fi

# ==============================================================================
# AJOUT SP√âCIFIQUE EXERCICE 3 : INITIALISATION SQL
# ==============================================================================
# On v√©rifie si creation.sql existe dans le dossier du projet
cd "$PROJECT_DIR_ABS"
if [ -f "creation.sql" ] && [ -f "insertion.sql" ]; then
  echo "[INFO] üõ†  D√©tection des scripts SQL. Initialisation de la BDD..."

  # D√©terminer le nom du conteneur PostgreSQL
  POSTGRES_CONTAINER="bigyellowdata-postgres-dw-1"
  if ! docker ps | grep -q "$POSTGRES_CONTAINER"; then
    POSTGRES_CONTAINER="postgres-dw"
  fi
  echo "[INFO] Utilisation du conteneur PostgreSQL: $POSTGRES_CONTAINER"

  # 1. Ex√©cuter creation.sql (Recr√©e les tables)
  echo "[INFO] üìã Cr√©ation du sch√©ma et des tables..."
  docker exec -i "$POSTGRES_CONTAINER" psql -U user_dw -d nyc_data_warehouse < creation.sql

  if [ $? -ne 0 ]; then
    echo "‚ùå Erreur lors de l'ex√©cution de creation.sql"
    exit 1
  fi

  # 2. V√©rifier et charger le fichier taxi_zone_lookup.csv
  CSV_LOCAL_PATH="data/raw/taxi_zone_lookup.csv"
  if [ ! -f "$CSV_LOCAL_PATH" ]; then
    CSV_LOCAL_PATH="../data/raw/taxi_zone_lookup.csv"
  fi

  if [ ! -f "$CSV_LOCAL_PATH" ]; then
    echo "[INFO] üì• T√©l√©chargement de taxi_zone_lookup.csv..."
    mkdir -p data/raw 2>/dev/null || mkdir -p ../data/raw 2>/dev/null
    curl -sS -o "${CSV_LOCAL_PATH}" "https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv"
    if [ $? -ne 0 ]; then
      echo "‚ö†Ô∏è  Impossible de t√©l√©charger taxi_zone_lookup.csv, continuez quand m√™me..."
    else
      echo "[INFO] ‚úÖ CSV t√©l√©charg√© avec succ√®s"
    fi
  fi

  # 3. Copier le CSV dans le conteneur PostgreSQL
  if [ -f "$CSV_LOCAL_PATH" ]; then
    echo "[INFO] üì¶ Copie de taxi_zone_lookup.csv dans le conteneur..."
    docker cp "$CSV_LOCAL_PATH" "$POSTGRES_CONTAINER":/tmp/taxi_zone_lookup.csv
    if [ $? -eq 0 ]; then
      echo "[INFO] ‚úÖ CSV copi√© dans le conteneur"
    fi
  fi

  # 4. Ex√©cuter insertion.sql (Donn√©es de r√©f√©rence)
  echo "[INFO] üìä Insertion des donn√©es de r√©f√©rence..."
  docker exec -i "$POSTGRES_CONTAINER" psql -U user_dw -d nyc_data_warehouse < insertion.sql

  if [ $? -eq 0 ]; then
    echo "[INFO] ‚úÖ Base de donn√©es initialis√©e avec succ√®s"
  else
    echo "‚ùå Erreur lors de l'insertion des donn√©es de r√©f√©rence"
    exit 1
  fi

  # Cleanup
  docker exec "$POSTGRES_CONTAINER" rm -f /tmp/taxi_zone_lookup.csv 2>/dev/null || true

else
  echo "[INFO] Pas de scripts SQL trouv√©s, on passe directement au job Spark."
fi
# ==============================================================================

# --- 6) Lancer spark-submit (seulement si pas SQL pur) ---
if [ "$IS_SQL_ONLY" = false ]; then
  echo "[INFO] Lancement de spark-submit..."

  # J'ai ajout√© les --packages et --conf n√©cessaires pour que l'exo 3 fonctionne
  docker exec -i spark-master /opt/spark/bin/spark-submit \
    --class "$MAIN_CLASS" \
    --master spark://spark-master:7077 \
    --packages org.postgresql:postgresql:42.6.0,org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262 \
    --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem \
    --conf spark.hadoop.fs.s3a.path.style.access=true \
    --conf spark.hadoop.fs.s3a.connection.ssl.enabled=false \
    /opt/spark/"$JAR_NAME"
else
  echo "[INFO] ‚è≠Ô∏è  Pas de job Spark √† ex√©cuter (projet SQL pur)"
fi

# Utiliser le m√™me nom de conteneur que d√©fini plus haut
POSTGRES_CONTAINER="${POSTGRES_CONTAINER:-bigyellowdata-postgres-dw-1}"
if ! docker ps | grep -q "$POSTGRES_CONTAINER"; then
  POSTGRES_CONTAINER="postgres-dw"
fi

# G√©n√©rer dim_date √† partir des donn√©es r√©elles de fact_trip
if [ -f "populate_dim_date.sql" ]; then
  echo "[INFO] üìÖ G√©n√©ration de dim_date √† partir des donn√©es r√©elles..."
  docker exec -i "$POSTGRES_CONTAINER" psql -U user_dw -d nyc_data_warehouse < populate_dim_date.sql
  if [ $? -eq 0 ]; then
    echo "[INFO] ‚úÖ dim_date g√©n√©r√©e avec succ√®s"
  else
    echo "‚ö†Ô∏è  Erreur lors de la g√©n√©ration de dim_date"
  fi
fi

if [ -f "aggregation.sql" ]; then
  echo "[INFO] üìä Calcul des Agr√©gats (Data Marts)..."

  docker exec -i "$POSTGRES_CONTAINER" psql -U user_dw -d nyc_data_warehouse < aggregation.sql

  if [ $? -eq 0 ]; then
    echo "[INFO] ‚úÖ Agr√©gations termin√©es avec succ√®s"
  else
    echo "‚ö†Ô∏è  Erreur lors des agr√©gations (normal si fact_trip est vide)"
  fi
else
  echo "[INFO] Pas de fichier aggregation.sql trouv√©."
fi

echo ""
echo "[INFO] üéâ PIPELINE COMPLET TERMIN√â AVEC SUCC√àS !"